â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./pom.xml
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
<project xmlns="http://maven.apache.org/POM/4.0.0"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>4.0.1</version>
	</parent>
	<groupId>com.indra.minsait.dvsmart.indexing</groupId>
	<artifactId>dvsmart_indexing_api</artifactId>
	<version>1.0.0-SNAPSHOT</version>
	<name>dvsmart_indexing_api</name>

	<properties>
		<java.version>21</java.version>
		<maven.compiler.source>21</maven.compiler.source>
		<maven.compiler.target>21</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<license.maven.plugin.version>5.0.0</license.maven.plugin.version>
		<maven.build.timestamp.format>yyyy</maven.build.timestamp.format>
		<!-- Other dependencies -->
		<sshj.version>0.38.0</sshj.version>
	</properties>

	<dependencies>
		<!-- Spring Boot Starters -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-validation</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-mongodb</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>

		<!-- Spring Batch -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-batch</artifactId>
		</dependency>

		<!-- Spring Integration Core -->
		<dependency>
			<groupId>org.springframework.integration</groupId>
			<artifactId>spring-integration-core</artifactId>
		</dependency>

		<!-- Spring Integration SFTP (SSHJ) -->
		<dependency>
			<groupId>org.springframework.integration</groupId>
			<artifactId>spring-integration-sftp</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.batch</groupId>
			<artifactId>spring-batch-integration</artifactId>
		</dependency>

		<!-- SSHJ for SFTP -->
		<dependency>
			<groupId>com.hierynomus</groupId>
			<artifactId>sshj</artifactId>
			<version>${sshj.version}</version>
		</dependency>

		<!-- Lombok -->
		<dependency>
			<groupId>org.projectlombok</groupId>
			<artifactId>lombok</artifactId>
			<scope>provided</scope>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-devtools</artifactId>
			<scope>runtime</scope>
			<optional>true</optional>
		</dependency>

		<!-- Spring Boot Configuration Processor -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-configuration-processor</artifactId>
			<optional>true</optional>
		</dependency>

		<!-- Testing -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.springframework.batch</groupId>
			<artifactId>spring-batch-test</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.springframework.integration</groupId>
			<artifactId>spring-integration-test</artifactId>
			<scope>test</scope>
		</dependency>

		<!-- Apache Commons Pool para gestiÃ³n de pool lazy -->
		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-pool2</artifactId>
		</dependency>

	    <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <scope>runtime</scope>
        </dependency> 

		<dependency>
		    <groupId>org.springframework.boot</groupId>
		    <artifactId>spring-boot-starter-jdbc</artifactId>
		</dependency>

	</dependencies>

	<build>
		<finalName>${project.artifactId}</finalName>
		<plugins>

			<!-- Maven Compiler Plugin -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>${java.version}</source>
					<target>${java.version}</target>
					<encoding>${project.build.sourceEncoding}</encoding>
					<annotationProcessorPaths>
						<path>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
							<version>${lombok.version}</version>
						</path>
						<path>
							<groupId>org.springframework.boot</groupId>
							<artifactId>spring-boot-configuration-processor</artifactId>
							<version>4.0.0</version>
						</path>
					</annotationProcessorPaths>
				</configuration>
			</plugin>

			<!-- Spring Boot Maven Plugin -->
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<configuration>
					<excludes>
						<exclude>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</exclude>
					</excludes>
				</configuration>
				<executions>
					<execution>
						<goals>
							<goal>repackage</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- CopyRight Plugin -->
			<plugin>
				<groupId>com.mycila</groupId>
				<artifactId>license-maven-plugin</artifactId>
				<version>${license.maven.plugin.version}</version>
				<configuration>
					<!-- Ruta del banner -->
					<header>src/main/resources/license-header.txt</header>

					<!-- Aplicar solo a archivos donde corresponde -->
					<includes>
						<include>**/*.java</include>
					</includes>

					<!-- Evitar modificar cÃ³digo generado o configuraciones -->
					<excludes>
						<exclude>**/target/**</exclude>
						<exclude>**/generated/**</exclude>
					</excludes>

					<!-- Variables dinÃ¡micas -->
					<properties>
						<year>${maven.build.timestamp}</year>
					</properties>

					<!-- Etiquetas conocidas para insertar correctamente el
					header -->
					<mapping>
						<java>SLASHSTAR_STYLE</java>
					</mapping>

					<!-- Configuraciones adicionales importantes -->
					<strictCheck>true</strictCheck>
					<useDefaultExcludes>true</useDefaultExcludes>
				</configuration>

				<executions>
					<!-- Ejecuta el format en la fase process-sources (antes de
					compile) -->
					<execution>
						<id>apply-license-headers</id>
						<phase>process-sources</phase>
						<goals>
							<goal>format</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- Maven Surefire Plugin (para tests) -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<!--				<version>3.0.0</version>-->
				<configuration>
					<includes>
						<include>**/*Test.java</include>
						<include>**/*Tests.java</include>
					</includes>
				</configuration>
			</plugin>

			<!-- Maven Resources Plugin -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-resources-plugin</artifactId>
				<!--				<version>3.3.1</version>-->
				<configuration>
					<encoding>${project.build.sourceEncoding}</encoding>
				</configuration>
			</plugin>
		</plugins>
	</build>

	<!-- Profiles -->
	<profiles>
		<!-- Development Profile -->
		<profile>
			<id>dev</id>
			<activation>
				<activeByDefault>true</activeByDefault>
			</activation>
			<properties>
				<spring.profiles.active>dev</spring.profiles.active>
			</properties>
		</profile>

		<!-- Production Profile -->
		<profile>
			<id>prod</id>
			<properties>
				<spring.profiles.active>prod</spring.profiles.active>
			</properties>
		</profile>
	</profiles>

</project>-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/in/dto/JobIndexRequest.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.in.dto;

import java.util.HashMap;
import java.util.Map;

import jakarta.validation.constraints.NotBlank;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 23-12-2025 at 13:38:53
 * File: JobIndexRequest.java
 */

public record JobIndexRequest(
		@NotBlank(message = "Job name is required")
	    String jobName,
	    Map<String, Object> parameters
) {
    public JobIndexRequest {
        // Inicializar parÃ¡metros vacÃ­os si es null
        if (parameters == null) {
            parameters = new HashMap<>();
        }
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/in/rest/BatchIndexingController.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.in.rest;
import com.indra.minsait.dvsmart.indexing.adapter.in.dto.JobIndexRequest;
import com.indra.minsait.dvsmart.indexing.application.port.in.StartIndexFullUseCase;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import java.util.Map;
import jakarta.validation.*;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 13:25:04
 * File: BatchReorganizeController.java
 */

@Slf4j
@RestController
@RequestMapping("/api/batch/index")
@RequiredArgsConstructor
public class BatchIndexingController {

    private final StartIndexFullUseCase startIndexingFullUseCase;

    @PostMapping("/full")
    public ResponseEntity<Map<String, Object>> startFullReorganization(@Valid @RequestBody JobIndexRequest request) {
        log.info("Received request to start full indexing of disorganized files");
        
        Long jobExecutionId = startIndexingFullUseCase.execute(
        		request.jobName(),
        		request.parameters()
        		);
        
        return ResponseEntity.accepted()
                .body(Map.of(
                    "message", "Batch job started successfully",
                    "jobExecutionId", jobExecutionId,
                    "status", "ACCEPTED"
                ));
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/in/rest/MonitoringController.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.in.rest;

import com.indra.minsait.dvsmart.indexing.infrastructure.sftp.CustomLazySftpSessionFactory;
import com.indra.minsait.dvsmart.indexing.infrastructure.sftp.SftpPoolMonitor;
import com.indra.minsait.dvsmart.indexing.infrastructure.sftp.SftpPoolMonitor.ExtendedPoolStats;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.batch.core.BatchStatus;
import org.springframework.batch.core.job.JobExecution;
import org.springframework.batch.core.job.JobInstance;
import org.springframework.batch.core.launch.NoSuchJobException;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.StepExecution;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;
import java.time.Duration;
import java.time.LocalDateTime;
import java.util.*;
import java.util.stream.Collectors;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 18-12-2025 at 16:29:47
 * File: MonitoringController.java
 */

/**
 * Endpoint para monitorear el estado del pool SFTP y Jobs de Spring Batch.
 * 
 * Endpoints disponibles:
 * 
 * SFTP Pool:
 * - GET  /api/monitoring/sftp-pool           - EstadÃ­sticas bÃ¡sicas
 * - GET  /api/monitoring/sftp-pool/extended  - EstadÃ­sticas extendidas
 * - GET  /api/monitoring/sftp-pool/health    - Estado de salud
 * - POST /api/monitoring/sftp-pool/evict     - Forzar limpieza
 * - POST /api/monitoring/sftp-pool/reset     - Reset contadores
 * - POST /api/monitoring/sftp-pool/log       - Log manual
 * 
 * Batch Jobs:
 * - GET  /api/monitoring/jobs                - Lista todos los jobs
 * - GET  /api/monitoring/jobs/running        - Jobs en ejecuciÃ³n
 * - GET  /api/monitoring/jobs/latest         - Ãšltima ejecuciÃ³n de cada job
 * - GET  /api/monitoring/jobs/{name}         - Historial de un job especÃ­fico
 * - GET  /api/monitoring/jobs/execution/{id} - Detalle de una ejecuciÃ³n
 * - GET  /api/monitoring/jobs/stats          - EstadÃ­sticas globales
 */
@Slf4j
@RestController
@RequestMapping("/api/monitoring")
@RequiredArgsConstructor
public class MonitoringController {

    private final SftpPoolMonitor poolMonitor;
    private final JobRepository jobExplorer;

    /* ========================================
     * SFTP POOL MONITORING
     * ======================================== */

    @GetMapping("/sftp-pool")
    public ResponseEntity<Map<String, Object>> getSftpPoolStats() {
        var stats = poolMonitor.getStats();
        poolMonitor.logStats();
        
        return ResponseEntity.ok(Map.of(
            "active", stats.active(),
            "idle", stats.idle(),
            "maxTotal", stats.maxTotal(),
            "totalCreated", stats.created(),
            "totalDestroyed", stats.destroyed(),
            "utilizationPercent", calculateUtilization(stats),
            "availableSlots", stats.maxTotal() - stats.active()
        ));
    }

    @GetMapping("/sftp-pool/extended")
    public ResponseEntity<ExtendedPoolStats> getExtendedStats() {
        ExtendedPoolStats stats = poolMonitor.getExtendedStats();
        log.info("Extended stats requested: {}", stats.getHealthStatus());
        return ResponseEntity.ok(stats);
    }

    @GetMapping("/sftp-pool/health")
    public ResponseEntity<Map<String, Object>> getPoolHealth() {
        ExtendedPoolStats stats = poolMonitor.getExtendedStats();
        String healthStatus = stats.getHealthStatus();
        boolean isHealthy = stats.isHealthy();
        
        log.info("Pool health check: status={}, healthy={}", healthStatus, isHealthy);
        
        return ResponseEntity.ok(Map.of(
            "status", healthStatus,
            "healthy", isHealthy,
            "details", Map.of(
                "active", stats.active(),
                "idle", stats.idle(),
                "utilizationPercent", stats.utilizationPercent(),
                "totalFailures", stats.totalFailures(),
                "totalBorrows", stats.totalBorrows()
            )
        ));
    }

    @PostMapping("/sftp-pool/evict")
    public ResponseEntity<Map<String, Object>> forceEviction() {
        log.info("Manual eviction triggered");
        
        var statsBefore = poolMonitor.getStats();
        poolMonitor.forceEviction();
        var statsAfter = poolMonitor.getStats();
        
        return ResponseEntity.ok(Map.of(
            "message", "Eviction triggered",
            "before", Map.of(
                "active", statsBefore.active(),
                "idle", statsBefore.idle()
            ),
            "after", Map.of(
                "active", statsAfter.active(),
                "idle", statsAfter.idle()
            )
        ));
    }

    @PostMapping("/sftp-pool/reset")
    public ResponseEntity<Map<String, Object>> resetCounters() {
        log.warn("Pool monitor counters reset requested");
        poolMonitor.resetCounters();
        
        return ResponseEntity.ok(Map.of(
            "message", "Counters reset successfully",
            "timestamp", System.currentTimeMillis()
        ));
    }

    @PostMapping("/sftp-pool/log")
    public ResponseEntity<Map<String, Object>> logStats() {
        poolMonitor.logStats();
        return ResponseEntity.ok(Map.of(
            "message", "Stats logged to server logs",
            "checkLogs", true
        ));
    }

    /* ========================================
     * BATCH JOBS MONITORING
     * ======================================== */

    /**
     * GET /api/monitoring/jobs
     */
    @GetMapping("/jobs")
    public ResponseEntity<Map<String, Object>> getAllJobs() {
        List<String> jobNames = jobExplorer.getJobNames();
        
        log.info("ğŸ“‹ Jobs available: {}", jobNames);
        
        return ResponseEntity.ok(Map.of(
            "jobNames", jobNames,
            "totalJobs", jobNames.size()
        ));
    }

    /**
     * GET /api/monitoring/jobs/running
     */
    @GetMapping("/jobs/running")
    public ResponseEntity<Map<String, Object>> getRunningJobs() {
        Set<JobExecution> runningExecutions = jobExplorer.findRunningJobExecutions(null);
        
        List<Map<String, Object>> runningJobs = runningExecutions.stream()
            .map(this::buildJobExecutionSummary)
            .collect(Collectors.toList());
        
        log.info("ğŸƒ Running jobs: {}", runningJobs.size());
        
        return ResponseEntity.ok(Map.of(
            "runningJobs", runningJobs,
            "count", runningJobs.size()
        ));
    }

    /**
     * GET /api/monitoring/jobs/latest
     */
    @GetMapping("/jobs/latest")
    public ResponseEntity<Map<String, Object>> getLatestExecutions() {
        List<String> jobNames = jobExplorer.getJobNames();
        
        List<Map<String, Object>> latestExecutions = jobNames.stream()
            .map(jobName -> {
                List<JobInstance> instances = jobExplorer.getJobInstances(jobName, 0, 1);
                if (!instances.isEmpty()) {
                    JobInstance instance = instances.get(0);
                    List<JobExecution> executions = jobExplorer.getJobExecutions(instance);
                    if (!executions.isEmpty()) {
                        JobExecution latest = executions.get(0);
                        return buildJobExecutionDetail(latest);
                    }
                }
                return null;
            })
            .filter(Objects::nonNull)
            .collect(Collectors.toList());
        
        log.info("ğŸ“Š Latest executions: {}", latestExecutions.size());
        
        return ResponseEntity.ok(Map.of(
            "latestExecutions", latestExecutions
        ));
    }

    /**
     * GET /api/monitoring/jobs/{jobName}
     * @throws NoSuchJobException 
     */
    @GetMapping("/jobs/{jobName}")
    public ResponseEntity<Map<String, Object>> getJobHistory(
            @PathVariable String jobName,
            @RequestParam(defaultValue = "0") int page,
            @RequestParam(defaultValue = "10") int size) throws NoSuchJobException {
        
        List<JobInstance> instances = jobExplorer.getJobInstances(jobName, page, size);
        
        List<Map<String, Object>> executions = instances.stream()
            .flatMap(instance -> jobExplorer.getJobExecutions(instance).stream())
            .sorted(Comparator.comparing(JobExecution::getCreateTime).reversed())
            .map(this::buildJobExecutionDetail)
            .collect(Collectors.toList());
        
        long totalCount = jobExplorer.getJobInstanceCount(jobName);
        
        log.info("ğŸ“œ Job history for '{}': {} executions (page {}/{})", 
                 jobName, executions.size(), page, size);
        
        return ResponseEntity.ok(Map.of(
            "jobName", jobName,
            "executions", executions,
            "totalExecutions", totalCount,
            "page", page,
            "size", size
        ));
    }

    /**
     * GET /api/monitoring/jobs/execution/{executionId}
     */
    @GetMapping("/jobs/execution/{executionId}")
    public ResponseEntity<Map<String, Object>> getExecutionDetail(@PathVariable Long executionId) {
        JobExecution execution = jobExplorer.getJobExecution(executionId);
        
        if (execution == null) {
            return ResponseEntity.notFound().build();
        }
        
        Map<String, Object> detail = buildJobExecutionDetail(execution);
        
        // Agregar detalle de steps
        Collection<StepExecution> stepExecutions = execution.getStepExecutions();
        List<Map<String, Object>> steps = stepExecutions.stream()
            .map(this::buildStepExecutionDetail)
            .collect(Collectors.toList());
        
        detail.put("steps", steps);
        
        log.info("ğŸ” Execution detail requested: {}", executionId);
        
        return ResponseEntity.ok(detail);
    }

    /**
     * GET /api/monitoring/jobs/stats
     * @throws NoSuchJobException 
     */
    @GetMapping("/jobs/stats")
    public ResponseEntity<Map<String, Object>> getGlobalStats() throws NoSuchJobException {
        List<String> jobNames = jobExplorer.getJobNames();
        
        Map<BatchStatus, Long> statusCounts = new HashMap<>();
        long totalExecutions = 0;
        long runningExecutions = 0;
        long completedExecutions = 0;
        long failedExecutions = 0;
        
        for (String jobName : jobNames) {
            long count = jobExplorer.getJobInstanceCount(jobName);
            totalExecutions += count;
            
            List<JobInstance> instances = jobExplorer.getJobInstances(jobName, 0, (int)count);
            for (JobInstance instance : instances) {
                List<JobExecution> executions = jobExplorer.getJobExecutions(instance);
                for (JobExecution execution : executions) {
                    BatchStatus status = execution.getStatus();
                    statusCounts.merge(status, 1L, Long::sum);
                    
                    if (status == BatchStatus.STARTED || status == BatchStatus.STARTING) {
                        runningExecutions++;
                    } else if (status == BatchStatus.COMPLETED) {
                        completedExecutions++;
                    } else if (status == BatchStatus.FAILED) {
                        failedExecutions++;
                    }
                }
            }
        }
        
        Map<String, Long> byStatus = statusCounts.entrySet().stream()
            .collect(Collectors.toMap(
                e -> e.getKey().name(),
                Map.Entry::getValue
            ));
        
        log.info("ğŸ“ˆ Global stats: {} jobs, {} executions", jobNames.size(), totalExecutions);
        
        return ResponseEntity.ok(Map.of(
            "totalJobs", jobNames.size(),
            "totalExecutions", totalExecutions,
            "runningExecutions", runningExecutions,
            "completedExecutions", completedExecutions,
            "failedExecutions", failedExecutions,
            "byStatus", byStatus
        ));
    }

    /**
     * GET /api/monitoring/health
     */
    @GetMapping("/health")
    public ResponseEntity<Map<String, Object>> getSystemHealth() {
        ExtendedPoolStats poolStats = poolMonitor.getExtendedStats();
        boolean poolHealthy = poolStats.isHealthy();
        
        Set<JobExecution> runningJobs = jobExplorer.findRunningJobExecutions(null);
        
        // âœ… CORRECCIÃ“N: Un job estÃ¡ saludable si NO estÃ¡ en estado FAILED
        // Jobs en STARTED/STARTING son normales (no son degraded)
        boolean jobsHealthy = runningJobs.stream()
            .allMatch(exec -> exec.getStatus() != BatchStatus.FAILED);
        
        // âœ… CORRECCIÃ“N: Sistema saludable si AMBOS componentes estÃ¡n OK
        boolean systemHealthy = poolHealthy && jobsHealthy;
        
        String batchStatus;
        if (runningJobs.isEmpty()) {
            batchStatus = "IDLE";  // âœ… Sin jobs corriendo = IDLE (no DEGRADED)
        } else if (jobsHealthy) {
            batchStatus = "RUNNING";  // âœ… Jobs corriendo sin fallos = RUNNING
        } else {
            batchStatus = "DEGRADED";  // âœ… Jobs con fallos = DEGRADED
        }
        
        return ResponseEntity.ok(Map.of(
            "status", systemHealthy ? "UP" : "DEGRADED",
            "components", Map.of(
                "sftp", Map.of(
                    "status", poolStats.getHealthStatus(),
                    "active", poolStats.active(),
                    "available", poolStats.maxTotal() - poolStats.active()
                ),
                "batch", Map.of(
                    "status", batchStatus,
                    "runningJobs", runningJobs.size()
                )
            )
        ));
    }

    /* ========================================
     * HELPER METHODS
     * ======================================== */

    private double calculateUtilization(CustomLazySftpSessionFactory.PoolStats stats) {
        if (stats.maxTotal() == 0) return 0.0;
        return (double) stats.active() / stats.maxTotal() * 100.0;
    }

    private Map<String, Object> buildJobExecutionSummary(JobExecution execution) {
        Map<String, Object> summary = new LinkedHashMap<>();
        summary.put("executionId", execution.getId());
        summary.put("jobName", execution.getJobInstance().getJobName());
        summary.put("status", execution.getStatus().name());
        summary.put("startTime", execution.getStartTime());
        
        if (execution.getEndTime() != null) {
            summary.put("endTime", execution.getEndTime());
            summary.put("duration", calculateDuration(execution));
        } else {
            summary.put("duration", calculateDuration(execution));
        }
        
        return summary;
    }

    private Map<String, Object> buildJobExecutionDetail(JobExecution execution) {
        Map<String, Object> detail = new LinkedHashMap<>();
        detail.put("executionId", execution.getId());
        detail.put("jobName", execution.getJobInstance().getJobName());
        detail.put("status", execution.getStatus().name());
        detail.put("createTime", execution.getCreateTime());
        detail.put("startTime", execution.getStartTime());
        detail.put("endTime", execution.getEndTime());
        detail.put("duration", calculateDuration(execution));
        detail.put("exitCode", execution.getExitStatus().getExitCode());
        detail.put("exitDescription", execution.getExitStatus().getExitDescription());
        
        // âœ… CORRECTO: Iterar sobre parameters() que retorna Set<JobParameter<?>>
        Map<String, Object> params = new LinkedHashMap<>();
        execution.getJobParameters().parameters().forEach(jobParameter -> {
            params.put(jobParameter.name(), jobParameter.value());
        });
        detail.put("parameters", params);
        
        return detail;
    }

    private Map<String, Object> buildStepExecutionDetail(StepExecution step) {
        Map<String, Object> detail = new LinkedHashMap<>();
        detail.put("stepName", step.getStepName());
        detail.put("status", step.getStatus().name());
        detail.put("readCount", step.getReadCount());
        detail.put("writeCount", step.getWriteCount());
        detail.put("commitCount", step.getCommitCount());
        detail.put("rollbackCount", step.getRollbackCount());
        detail.put("readSkipCount", step.getReadSkipCount());
        detail.put("processSkipCount", step.getProcessSkipCount());
        detail.put("writeSkipCount", step.getWriteSkipCount());
        detail.put("filterCount", step.getFilterCount());
        detail.put("startTime", step.getStartTime());
        detail.put("endTime", step.getEndTime());
        detail.put("duration", calculateStepDuration(step));
        detail.put("exitCode", step.getExitStatus().getExitCode());
        
        return detail;
    }

    private String calculateDuration(JobExecution execution) {
        if (execution.getStartTime() == null) {
            return "N/A";
        }
        
        LocalDateTime endTime = execution.getEndTime() != null 
            ? execution.getEndTime()
            : LocalDateTime.now();
        
        Duration duration = Duration.between(
            execution.getStartTime(),
            endTime
        );
        
        return formatDuration(duration);
    }

    private String calculateStepDuration(StepExecution step) {
        if (step.getStartTime() == null) {
            return "N/A";
        }
        
        LocalDateTime endTime = step.getEndTime() != null 
            ? step.getEndTime()
            : LocalDateTime.now();
        
        Duration duration = Duration.between(
            step.getStartTime(),
            endTime
        );
        
        return formatDuration(duration);
    }

    private String formatDuration(Duration duration) {
        long hours = duration.toHours();
        long minutes = duration.toMinutesPart();
        long seconds = duration.toSecondsPart();
        
        if (hours > 0) {
            return String.format("%dh %dm %ds", hours, minutes, seconds);
        } else if (minutes > 0) {
            return String.format("%dm %ds", minutes, seconds);
        } else {
            return String.format("%ds", seconds);
        }
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/out/batch/config/BatchIndexFullConfig.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.out.batch.config;

import com.indra.minsait.dvsmart.indexing.adapter.out.batch.processor.MetadataExtractorProcessor;
import com.indra.minsait.dvsmart.indexing.adapter.out.batch.reader.DirectoryQueueItemReader;
import com.indra.minsait.dvsmart.indexing.adapter.out.batch.writer.BulkUpsertMongoItemWriter;
import com.indra.minsait.dvsmart.indexing.domain.model.ArchivoMetadata;
import com.indra.minsait.dvsmart.indexing.domain.model.SftpFileEntry;
import com.indra.minsait.dvsmart.indexing.domain.service.DirectoryDiscoveryService;
import com.indra.minsait.dvsmart.indexing.infrastructure.config.BatchConfigProperties;
import com.indra.minsait.dvsmart.indexing.infrastructure.config.SftpConfigProperties;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.batch.core.configuration.JobRegistry;
import org.springframework.batch.core.configuration.annotation.StepScope;
import org.springframework.batch.core.configuration.support.MapJobRegistry;
import org.springframework.batch.core.job.Job;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.batch.core.job.parameters.RunIdIncrementer;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.Step;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.infrastructure.item.ItemReader;
import org.springframework.batch.integration.async.AsyncItemProcessor;
import org.springframework.batch.integration.async.AsyncItemWriter;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.task.TaskExecutor;
import org.springframework.integration.sftp.session.SftpRemoteFileTemplate;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
import java.io.IOException;
import java.util.concurrent.Future;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 13:23:54
 * File: BatchReorgFullConfig.java
 */

/**
 * ConfiguraciÃ³n del Job de IndexaciÃ³n Completa.
 * 
 * Flujo:
 * 1. Pre-procesamiento: Descubrir todos los directorios (una sola sesiÃ³n SFTP)
 * 2. Reader: Lee archivos directorio por directorio (usa pool lazy)
 * 3. Processor: Extrae metadata de cada archivo (paralelo, sin SFTP)
 * 4. Writer: Bulk upsert a MongoDB (paralelo, sin SFTP)
 * 
 * Ventajas del pool lazy:
 * - Reader usa pocas conexiones (1-2 tÃ­picamente)
 * - Conexiones se liberan automÃ¡ticamente al terminar
 * - No hay conexiones idle consumiendo recursos
 */
@Slf4j
@Configuration
@RequiredArgsConstructor
public class BatchIndexFullConfig {

    private final JobRepository jobRepository;
    private final DirectoryDiscoveryService directoryDiscoveryService;
    private final BulkUpsertMongoItemWriter bulkWriter;
    private final BatchConfigProperties batchProps;
    private final SftpConfigProperties sftpProps;
    private final MetadataExtractorProcessor metadataExtractorProcessor;
    private final BatchConfigProperties props;
    
    @Qualifier("sftpOriginTemplate")
    private final SftpRemoteFileTemplate sftpTemplate;

    @Bean
    JobRegistry jobRegistry() {
        return new MapJobRegistry();
    }

    @Bean(name = "indexingTaskExecutor")
    TaskExecutor indexingTaskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(batchProps.getThreadPoolSize());
        executor.setMaxPoolSize(batchProps.getThreadPoolSize());
        executor.setQueueCapacity(batchProps.getQueueCapacity());
        executor.setThreadNamePrefix("batch-index-async-");
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.setAwaitTerminationSeconds(60);
        executor.initialize();
        return executor;
    }

    /**
     * âœ… SOLUCIÃ“N: Reader con @StepScope para fresh discovery en cada job
     */
    @Bean
    @StepScope  // âœ… CRÃTICO: Nueva instancia por step
    ItemReader<SftpFileEntry> directoryQueueReader() {
        
        log.info("ğŸ”„ Creating NEW DirectoryQueueItemReader instance");
        
        return new DirectoryQueueItemReader(
            sftpTemplate, 
            directoryDiscoveryService, 
            sftpProps.getOrigin().getBaseDir()  // âœ… Pasar baseDir
        );
    }

    @Bean
    AsyncItemProcessor<SftpFileEntry, ArchivoMetadata> asyncMetadataProcessor() {
        AsyncItemProcessor<SftpFileEntry, ArchivoMetadata> asyncProcessor = 
            new AsyncItemProcessor<>(metadataExtractorProcessor);
        asyncProcessor.setTaskExecutor(indexingTaskExecutor());
        return asyncProcessor;
    }

    @Bean
    AsyncItemWriter<ArchivoMetadata> asyncBulkWriter() {
        return new AsyncItemWriter<>(bulkWriter);
    }

    @Bean
    Step indexingStep() {
        return new StepBuilder("indexingStep", jobRepository)
                .<SftpFileEntry, Future<ArchivoMetadata>>chunk(props.getChunkSize())
                .reader(directoryQueueReader())  // âœ… Spring inyectarÃ¡ nueva instancia
                .processor(asyncMetadataProcessor())
                .writer(asyncBulkWriter())
                .faultTolerant()
                .skipLimit(props.getSkipLimit())
                .skip(RuntimeException.class)
                .retryLimit(props.getRetryLimit())
                .retry(IOException.class)
                .build();
    }

    @Bean(name = "batchIndexFullJob")
    Job batchIndexFullJob() {
        return new JobBuilder("BATCH-INDEX-FULL", jobRepository)
                .incrementer(new RunIdIncrementer())
                .start(indexingStep())
                .build();
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/out/batch/processor/MetadataExtractorProcessor.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.out.batch.processor;

import com.indra.minsait.dvsmart.indexing.domain.model.ArchivoMetadata;
import com.indra.minsait.dvsmart.indexing.domain.model.SftpFileEntry;
import com.indra.minsait.dvsmart.indexing.domain.service.FileMetadataService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;

import java.time.Instant;

import org.springframework.batch.infrastructure.item.ItemProcessor;
import org.springframework.stereotype.Component;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 16-12-2025 at 16:33:10
 * File: MetadataExtractorProcessor.java
 */

/**
 * Processor que extrae metadata de archivos SFTP.
 * 
 * Responsabilidades:
 * - Filtrar directorios
 * - Filtrar archivos por extensiÃ³n (opcional)
 * - Validar tamaÃ±os (opcional)
 * - Delegar extracciÃ³n de metadata al servicio de dominio
 */
@Slf4j
@Component
@RequiredArgsConstructor
public class MetadataExtractorProcessor implements ItemProcessor<SftpFileEntry, ArchivoMetadata> {

    private final FileMetadataService metadataService;
    
    // ConfiguraciÃ³n opcional de filtros
    private static final long MIN_FILE_SIZE = 0;           // 0 bytes = sin filtro
    private static final long MAX_FILE_SIZE = Long.MAX_VALUE; // Sin lÃ­mite

    @Override
    public ArchivoMetadata process(SftpFileEntry entry) throws Exception {
        
        // Filtro 1: Skip nulls
        if (entry == null) {
            return null;
        }
        
        // Filtro 2: Skip directorios
        if (entry.isDirectory()) {
            log.trace("Skipping directory: {}", entry.getFullPath());
            return null;
        }
        
        // Filtro 3: Skip archivos ocultos
        if (entry.getFilename().startsWith(".")) {
            log.trace("Skipping hidden file: {}", entry.getFilename());
            return null;
        }
        
        // Filtro 4: Skip archivos temporales
        if (isTemporaryFile(entry.getFilename())) {
            log.trace("Skipping temporary file: {}", entry.getFilename());
            return null;
        }
        
        // Filtro 5: Validar tamaÃ±o
        if (entry.getSize() < MIN_FILE_SIZE || entry.getSize() > MAX_FILE_SIZE) {
            log.warn("Skipping file with invalid size: {} ({} bytes)", 
                     entry.getFullPath(), entry.getSize());
            return null;
        }
        
        // âœ… NUEVO: Capturar errores y retornar metadata con estado FAILED
        try {
            ArchivoMetadata metadata = metadataService.toMetadata(entry);
            log.trace("Processed: {} â†’ {}", entry.getFullPath(), metadata.getIdUnico());
            return metadata;
            
        } catch (Exception e) {
            log.error("Error processing file: {}", entry.getFullPath(), e);
            
            // âœ… CAMBIO: En lugar de lanzar excepciÃ³n, retornar metadata con error
            return createFailedMetadata(entry, e);
        }
    }

    /**
     * âœ… NUEVO: Crea metadata con estado FAILED cuando hay error
     */
    private ArchivoMetadata createFailedMetadata(SftpFileEntry entry, Exception error) {
        
        String idUnico;
        try {
            idUnico = metadataService.generateIdUnico(entry.getFullPath());
        } catch (Exception e) {
            // Fallback: usar hash simple del path
            idUnico = String.valueOf(entry.getFullPath().hashCode());
        }
        
        String errorMessage = String.format("%s: %s", 
            error.getClass().getSimpleName(), 
            error.getMessage() != null ? error.getMessage() : "Unknown error"
        );
        
        // Truncar mensaje si es muy largo
        if (errorMessage.length() > 500) {
            errorMessage = errorMessage.substring(0, 497) + "...";
        }
        
        return ArchivoMetadata.builder()
                .idUnico(idUnico)
                .sourcePath(entry.getFullPath())
                .fileName(entry.getFilename())
                .extension(extractExtension(entry.getFilename()))
                .fileSize(entry.getSize())
                .lastModificationDate(Instant.ofEpochMilli(entry.getModificationTime()))
                
                // âœ… Estado FAILED
                .indexing_status("FAILED")
                .indexing_indexedAt(Instant.now())
                .indexing_errorDescription(errorMessage)  // âœ… AQUÃ SE LLENA
                .build();
    }

    /**
     * âœ… NUEVO: Extrae extensiÃ³n de forma segura
     */
    private String extractExtension(String filename) {
        try {
            if (filename == null || !filename.contains(".")) {
                return "";
            }
            int lastDot = filename.lastIndexOf('.');
            return filename.substring(lastDot + 1).toLowerCase();
        } catch (Exception e) {
            return "";
        }
    }
    
    /**
     * Verifica si es un archivo temporal.
     */
    private boolean isTemporaryFile(String filename) {
        String lower = filename.toLowerCase();
        return lower.endsWith(".tmp") 
            || lower.endsWith(".temp")
            || lower.endsWith(".bak")
            || lower.endsWith("~")
            || lower.startsWith("~$");  // MS Office temp files
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/out/batch/reader/DirectoryQueueItemReader.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.out.batch.reader;

import com.indra.minsait.dvsmart.indexing.domain.model.SftpFileEntry;
import com.indra.minsait.dvsmart.indexing.domain.service.DirectoryDiscoveryService;
import lombok.extern.slf4j.Slf4j;
import org.apache.sshd.sftp.client.SftpClient;
import org.springframework.batch.infrastructure.item.ExecutionContext;
import org.springframework.batch.infrastructure.item.ItemReader;
import org.springframework.batch.infrastructure.item.ItemStream;
import org.springframework.integration.sftp.session.SftpRemoteFileTemplate;
import java.util.LinkedList;
import java.util.Queue;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 16-12-2025 at 14:55:25
 * File: DirectoryQueueItemReader.java
 */

/**
 * Reader optimizado con LAZY DISCOVERY.
 * 
 * ESTRATEGIA HYBRID STREAMING:
 * - Primera llamada a read(): Ejecuta discovery completo de directorios
 * - Siguientes llamadas: Procesa archivos directorio por directorio
 * - Memoria: O(D) donde D = archivos en el directorio actual
 * 
 * Ventajas:
 * - Discovery se ejecuta solo cuando se lanza el job (no al arrancar la app)
 * - Thread-safe con SftpRemoteFileTemplate
 * - Sesiones SFTP del pool lazy se usan eficientemente
 */
@Slf4j
public class DirectoryQueueItemReader implements ItemReader<SftpFileEntry>, ItemStream {

    private final SftpRemoteFileTemplate sftpTemplate;
    private final DirectoryDiscoveryService discoveryService;
    private final String baseDir;
    
    private Queue<String> directoryQueue;
    private Queue<SftpFileEntry> currentDirectoryFiles;
    
    private int totalFilesRead = 0;
    private int directoriesProcessed = 0;
    private boolean discoveryCompleted = false;

    /**
     * âœ… CAMBIO: Constructor solo recibe baseDir
     */
    public DirectoryQueueItemReader(
            SftpRemoteFileTemplate sftpTemplate,
            DirectoryDiscoveryService discoveryService,
            String baseDir) {
        this.sftpTemplate = sftpTemplate;
        this.discoveryService = discoveryService;
        this.baseDir = baseDir;
        this.currentDirectoryFiles = new LinkedList<>();
    }

    // âœ… NUEVO: Implementar ItemStream para control de ciclo de vida
    @Override
    public void open(ExecutionContext executionContext) {
        log.info("========================================");
        log.info("ğŸ”„ OPEN: Initializing DirectoryQueueItemReader");
        log.info("Base directory: {}", baseDir);
        log.info("========================================");
        
        this.discoveryCompleted = false;
        this.directoryQueue = null;
        this.currentDirectoryFiles.clear();
        this.totalFilesRead = 0;
        this.directoriesProcessed = 0;
    }

    @Override
    public void update(ExecutionContext executionContext) {
        executionContext.putInt("directoriesProcessed", directoriesProcessed);
        executionContext.putInt("totalFilesRead", totalFilesRead);
    }

    @Override
    public void close() {
        log.info("========================================");
        log.info("ğŸ›‘ CLOSE: Cleaning up DirectoryQueueItemReader");
        log.info("Final stats: {} files, {} directories", totalFilesRead, directoriesProcessed);
        log.info("========================================");
        
        if (directoryQueue != null) {
            directoryQueue.clear();
        }
        currentDirectoryFiles.clear();
    }

    @Override
    public SftpFileEntry read() throws Exception {
        
        // âœ… LAZY DISCOVERY: Solo la primera vez
        if (!discoveryCompleted) {
            executeDirectoryDiscovery();
            discoveryCompleted = true;
        }
        
        // Retornar archivos del directorio actual
        if (!currentDirectoryFiles.isEmpty()) {
            totalFilesRead++;
            return currentDirectoryFiles.poll();
        }
        
        // Si no hay mÃ¡s directorios, terminar
        if (directoryQueue == null || directoryQueue.isEmpty()) {
            log.info("========================================");
            log.info("âœ… INDEXING COMPLETED");
            log.info("Total files indexed: {}", totalFilesRead);
            log.info("Total directories processed: {}", directoriesProcessed);
            log.info("========================================");
            return null;
        }
        
        // âœ… CRÃTICO: Cargar siguiente directorio
        String nextDirectory = directoryQueue.poll();  // âœ… poll() remueve de la queue
        loadDirectoryFiles(nextDirectory);
        directoriesProcessed++;
        
        // Log progreso
        if (directoriesProcessed % 100 == 0) {
            log.info("ğŸ“Š Progress: {} directories processed, {} files indexed", 
                     directoriesProcessed, totalFilesRead);
        }
        
        return read(); // RecursiÃ³n para retornar primer archivo
    }

    /**
     * âœ… Ejecuta discovery completo FRESH
     */
    private void executeDirectoryDiscovery() {
        log.info("========================================");
        log.info("PHASE 1: DIRECTORY DISCOVERY");
        log.info("Base directory: {}", baseDir);
        log.info("========================================");
        
        long startTime = System.currentTimeMillis();
        
        // âœ… Discovery SIEMPRE fresh
        directoryQueue = discoveryService.discoverDirectories(sftpTemplate, baseDir);
        
        long duration = System.currentTimeMillis() - startTime;
        
        log.info("========================================");
        log.info("âœ… Discovery completed in {} ms ({} seconds)", duration, duration / 1000);
        log.info("Total directories to process: {}", directoryQueue.size());
        log.info("========================================");
        log.info("PHASE 2: FILE INDEXING");
        log.info("========================================");
    }

    /**
     * âœ… Carga archivos de UN directorio
     */
    private void loadDirectoryFiles(String directory) {
        try {
            sftpTemplate.execute(session -> {
                
                log.debug("ğŸ“‚ Scanning directory: {}", directory);
                
                SftpClient.DirEntry[] entries = session.list(directory);
                int filesInDir = 0;
                
                for (SftpClient.DirEntry entry : entries) {
                    String name = entry.getFilename();
                    
                    if (".".equals(name) || "..".equals(name)) {
                        continue;
                    }
                    
                    // âœ… Solo procesar ARCHIVOS
                    if (!entry.getAttributes().isDirectory()) {
                        String fullPath = directory.endsWith("/") 
                            ? directory + name 
                            : directory + "/" + name;
                        
                        SftpFileEntry fileEntry = SftpFileEntry.builder()
                                .fullPath(fullPath)
                                .filename(name)
                                .size(entry.getAttributes().getSize())
                                .modificationTime(entry.getAttributes().getModifyTime().toMillis())
                                .isDirectory(false)
                                .build();
                        
                        currentDirectoryFiles.add(fileEntry);
                        filesInDir++;
                    }
                }
                
                if (filesInDir > 0) {
                    log.debug("ğŸ“„ Loaded {} files from {}", filesInDir, directory);
                } else {
                    log.trace("ğŸ“­ Empty directory: {}", directory);
                }
                
                return null;
            });
            
        } catch (Exception e) {
            log.error("âŒ Error loading directory: {}", directory, e);
            throw new RuntimeException("Failed to load directory: " + directory, e);
        }
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/out/batch/writer/BulkUpsertMongoItemWriter.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.out.batch.writer;

import com.indra.minsait.dvsmart.indexing.adapter.out.persistence.mongodb.entity.DisorganizedFilesIndexDocument;
import com.indra.minsait.dvsmart.indexing.domain.model.ArchivoMetadata;
import com.mongodb.bulk.BulkWriteResult;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.batch.infrastructure.item.Chunk;
import org.springframework.batch.infrastructure.item.ItemWriter;
import org.springframework.data.mongodb.core.BulkOperations;
import org.springframework.data.mongodb.core.MongoTemplate;
import org.springframework.data.mongodb.core.query.Criteria;
import org.springframework.data.mongodb.core.query.Query;
import org.springframework.data.mongodb.core.query.Update;
import org.springframework.stereotype.Component;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 16-12-2025 at 14:44:55
 * File: BulkUpsertMongoItemWriter.java
 */

/**
 * Writer ultra-optimizado con bulk upsert.
 * 
 * Performance:
 * - Sin bulk: 100-200 docs/segundo
 * - Con bulk: 3000-5000 docs/segundo
 * 
 * Para 11M archivos:
 * - Sin bulk: ~15-30 horas
 * - Con bulk: ~30-60 minutos
 */
@Slf4j
@Component
@RequiredArgsConstructor
public class BulkUpsertMongoItemWriter implements ItemWriter<ArchivoMetadata> {

    private final MongoTemplate mongoTemplate;
    //private long totalInserted = 0;
    //private long totalUpdated = 0;

    @Override
    public void write(Chunk<? extends ArchivoMetadata> chunk) {
        
        BulkOperations bulkOps = mongoTemplate.bulkOps(
            BulkOperations.BulkMode.UNORDERED,
            DisorganizedFilesIndexDocument.class
        );
        
        int successCount = 0;
        int failedCount = 0;
        
        for (ArchivoMetadata metadata : chunk) {
            Query query = new Query(Criteria.where("idUnico").is(metadata.getIdUnico()));
            
            Update update = new Update()
                    .set("sourcePath", metadata.getSourcePath())
                    .set("fileName", metadata.getFileName())
                    .set("extension", metadata.getExtension())
                    .set("fileSize", metadata.getFileSize())
                    .set("lastModificationDate", metadata.getLastModificationDate())
                    
                    // âœ… Control de indexaciÃ³n (con error)
                    .set("indexing_status", metadata.getIndexing_status())
                    .set("indexing_indexedAt", metadata.getIndexing_indexedAt())
                    .set("indexing_errorDescription", metadata.getIndexing_errorDescription())  // âœ… CAMBIO
                    
                    // Estado inicial de reorganizaciÃ³n (solo si indexaciÃ³n exitosa)
                    .set("reorg_status", "FAILED".equals(metadata.getIndexing_status()) 
                        ? "SKIPPED"   // âœ… Si falla indexaciÃ³n, skip reorganizaciÃ³n
                        : "PENDING")
                    .set("reorg_attempts", 0)
                    
                    .setOnInsert("idUnico", metadata.getIdUnico());
            
            bulkOps.upsert(query, update);
            
            // âœ… NUEVO: Contar Ã©xitos y fallos
            if ("FAILED".equals(metadata.getIndexing_status())) {
                failedCount++;
            } else {
                successCount++;
            }
        }
        
        try {
            BulkWriteResult result = bulkOps.execute();
            
            int inserted = result.getInsertedCount();
            int updated = result.getModifiedCount();
            
            //totalInserted += inserted;
            //totalUpdated += updated;
            
            // âœ… NUEVO: Log mejorado con conteo de errores
            log.info("Bulk write completed: {} inserted, {} updated | Success: {}, Failed: {}", 
                     inserted, updated, successCount, failedCount);
            
            // âœ… NUEVO: Alertar si tasa de error es alta
            if (failedCount > 0) {
                double failureRate = (double) failedCount / (successCount + failedCount) * 100;
                if (failureRate > 5.0) {
                    log.warn("âš ï¸ HIGH FAILURE RATE: {:.2f}% ({}/{})", 
                        failureRate, failedCount, successCount + failedCount);
                }
            }
            
        } catch (Exception e) {
            log.error("Error in bulk write operation", e);
            throw new RuntimeException("Failed to write batch to MongoDB", e);
        }
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/adapter/out/persistence/mongodb/entity/DisorganizedFilesIndexDocument.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.adapter.out.persistence.mongodb.entity;

import lombok.Builder;
import lombok.Data;
import org.springframework.data.annotation.Id;
import org.springframework.data.mongodb.core.index.Indexed;
import org.springframework.data.mongodb.core.mapping.Document;
import java.time.Instant;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 16-12-2025 at 14:51:33
 * File: DisorganizedFilesIndexDocument.java
 */

/**
 * Documento MongoDB para colecciÃ³n files_index (UNIFICADA).
 * Soporta tanto indexaciÃ³n como reorganizaciÃ³n.
 */
@Data
@Builder
@Document(collection = "files_index")  // âœ… CAMBIO: ColecciÃ³n unificada
public class DisorganizedFilesIndexDocument {
    
    @Id
    private String id;
    
    @Indexed(unique = true)
    private String idUnico;           // SHA-256 del path completo
    
    // ========== METADATA DEL ARCHIVO ==========
    private String sourcePath;         // âœ… NUEVO (antes rutaOrigen)
    private String fileName;           // âœ… NUEVO (antes nombre)
    private String extension;
    private Long fileSize;             // âœ… NUEVO (antes tamanio)
    private Instant lastModificationDate; // âœ… NUEVO (antes mtime)
    
    // ========== CONTROL DE INDEXACIÃ“N ==========
    private String indexing_status;         // âœ… NUEVO: PENDING | COMPLETED | FAILED
    private Instant indexing_indexedAt;     // âœ… NUEVO
    private String indexing_errorDescription; // âœ… NUEVO
    
    // ========== CONTROL DE REORGANIZACIÃ“N ==========
    private String reorg_status;            // âœ… NUEVO: PENDING | PROCESSING | SUCCESS | FAILED | SKIPPED
    private String reorg_destinationPath;   // âœ… NUEVO
    private Instant reorg_reorganizedAt;    // âœ… NUEVO
    private Long reorg_jobExecutionId;      // âœ… NUEVO
    private Long reorg_durationMs;          // âœ… NUEVO
    private Integer reorg_attempts;         // âœ… NUEVO
    private String reorg_errorDescription;  // âœ… NUEVO
    private Instant reorg_lastAttemptAt;    // âœ… NUEVO
    
    // ========== METADATA DE NEGOCIO (OPCIONAL) ==========
    private String business_tipoDocumento;  // âœ… NUEVO
    private String business_codigoCliente;  // âœ… NUEVO
    private Integer business_anio;          // âœ… NUEVO
    private Integer business_mes;           // âœ… NUEVO
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/application/port/in/StartIndexFullUseCase.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.application.port.in;

import java.util.Map;

import jakarta.validation.constraints.NotBlank;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 12:30:07
 * File: StartReorganizeFullUseCase.java
 */

public interface StartIndexFullUseCase {
    Long execute(@NotBlank(message = "Job name is required") String string, Map<String, Object> map);
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/application/service/StartIndexFullService.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.application.service;

import com.indra.minsait.dvsmart.indexing.application.port.in.StartIndexFullUseCase;
import jakarta.validation.constraints.NotBlank;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import java.time.LocalDateTime;
import java.util.Map;
import org.springframework.batch.core.job.Job;
import org.springframework.batch.core.job.JobExecution;
import org.springframework.batch.core.job.parameters.JobParameters;
import org.springframework.batch.core.job.parameters.JobParametersBuilder;
import org.springframework.batch.core.launch.JobOperator;
import org.springframework.stereotype.Service;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 12:54:15
 * File: StartIndexFullService.java
 */

@Slf4j
@Service
@RequiredArgsConstructor
public class StartIndexFullService implements StartIndexFullUseCase {

	private final JobOperator jobOperator;
	
	private final Job batchIndexFullJob;
    
    @Override
    public Long execute(@NotBlank(message = "Job name is required") String string, Map<String, Object> map) {
        log.info("Starting FULL INDEXING JOB");
        
        try {
            validatePrerequisites();
            
            JobParametersBuilder paramsBuilder = new JobParametersBuilder();
            paramsBuilder.addLocalDateTime("timestamp", LocalDateTime.now(), true);
            map.forEach((key, value) -> {
                if (value instanceof String) {
                	paramsBuilder.addString(key, (String) value);
                } else if (value instanceof Long) {
                	paramsBuilder.addLong(key, (Long) value);
                } else if (value instanceof Double) {
                	paramsBuilder.addDouble(key, (Double) value);
                }
            });        
            JobParameters jobParameters = paramsBuilder.toJobParameters();
            log.info("Generated parameters: {}", jobParameters);

            JobExecution jobExecution = jobOperator.run(batchIndexFullJob, jobParameters);
            
            log.info("Job launched: executionId={}, status={}", 
                jobExecution.getId(), 
                jobExecution.getStatus());
            
            return jobExecution.getId();
            
        } catch (Exception e) {
            log.error("Failed to start job", e);
            throw new RuntimeException("Failed to start job: " + e.getMessage(), e);
        }
    }
    
    /**
     * Validaciones antes de ejecutar el job.
     * Evita iniciar si hay problemas conocidos.
     */
    private void validatePrerequisites() {
        log.debug("Validating job prerequisites...");
        
        // TODO: Agregar validaciones especÃ­ficas si son necesarias
        // Ejemplos:
        // - Verificar conectividad MongoDB
        // - Verificar conectividad SFTP (opcional, el pool lazy lo maneja)
        // - Verificar espacio en disco
        // - Verificar que no hay otro job corriendo (Batch lo maneja)
        
        log.debug("Prerequisites validation passed");
    }

}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/domain/model/ArchivoMetadata.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.domain.model;

import lombok.Builder;
import lombok.Data;
import java.time.Instant;

/**
 * Modelo de dominio que representa la metadata de un archivo indexado.
 */
@Data
@Builder
public class ArchivoMetadata {
    
    // IdentificaciÃ³n
    private String idUnico;
    
    // Metadata del archivo
    private String sourcePath;           // âœ… CAMBIO: antes rutaOrigen
    private String fileName;             // âœ… CAMBIO: antes nombre
    private String extension;
    private Long fileSize;               // âœ… CAMBIO: antes tamanio
    private Instant lastModificationDate; // âœ… CAMBIO: antes mtime
    
    // Control de indexaciÃ³n
    private String indexing_status;      // âœ… NUEVO
    private Instant indexing_indexedAt;  // âœ… NUEVO
    private String indexing_errorDescription;  // âœ… CAMBIO: Agregar campo
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/domain/model/SftpFileEntry.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.domain.model;

import lombok.Builder;
import lombok.Data;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 16-12-2025 at 14:35:09
 * File: SftpFileEntry.java
 */

/**
 * Representa una entrada de archivo en el listado de SFTP.
 * Modelo intermedio antes de convertir a ArchivoMetadata.
 */
@Data
@Builder
public class SftpFileEntry {
    private String fullPath;          // Path completo (/data/files/doc.pdf)
    private String filename;          // Nombre del archivo (doc.pdf)
    private long size;                // TamaÃ±o en bytes
    private long modificationTime;    // Unix timestamp (millis)
    private boolean isDirectory;      // true si es directorio
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/domain/service/DirectoryDiscoveryService.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.domain.service;

import lombok.extern.slf4j.Slf4j;
import org.apache.sshd.sftp.client.SftpClient;
import org.springframework.integration.sftp.session.SftpRemoteFileTemplate;
import org.springframework.stereotype.Service;
import java.util.LinkedList;
import java.util.Queue;
import java.util.concurrent.ConcurrentLinkedQueue;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 16-12-2025 at 14:40:25
 * File: DirectoryDiscoveryService.java
 */

/**
 * Servicio de descubrimiento de directorios usando SftpRemoteFileTemplate.
 */
@Slf4j
@Service
public class DirectoryDiscoveryService {

    /**
     * Descubre recursivamente todos los directorios bajo baseDir.
     * Usa template para manejo automÃ¡tico de sesiones.
     * 
     * @param sftpTemplate Template configurado
     * @param baseDir Directorio raÃ­z
     * @return Cola thread-safe de directorios
     */
    public Queue<String> discoverDirectories(
            SftpRemoteFileTemplate sftpTemplate,
            String baseDir) {
        
        log.info("Starting directory discovery from: {}", baseDir);
        
        Queue<String> directories = new ConcurrentLinkedQueue<>();
        
        try {
            // âœ… Una sola sesiÃ³n para todo el escaneo (mÃ¡s eficiente)
            sftpTemplate.execute(session -> {
                try {
					scanRecursive(session, baseDir, directories);
				} catch (Exception e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
                return null;
            });
            
            log.info("Directory discovery completed. Total: {}", directories.size());
            return directories;
            
        } catch (Exception e) {
            log.error("Failed to discover directories", e);
            throw new RuntimeException("Directory discovery failed", e);
        }
    }

    /**
     * Escaneo recursivo BFS interno (dentro de una sesiÃ³n).
     */
    private void scanRecursive(
            org.springframework.integration.file.remote.session.Session<SftpClient.DirEntry> session,
            String baseDir,
            Queue<String> directories) throws Exception {
        
        Queue<String> toExplore = new LinkedList<>();
        toExplore.add(baseDir);
        directories.add(baseDir);
        
        int dirCount = 0;
        
        while (!toExplore.isEmpty()) {
            String currentDir = toExplore.poll();
            
            SftpClient.DirEntry[] entries = session.list(currentDir);
            
            for (SftpClient.DirEntry entry : entries) {
                String name = entry.getFilename();
                
                if (".".equals(name) || "..".equals(name)) {
                    continue;
                }
                
                if (entry.getAttributes().isDirectory()) {
                    String fullPath = currentDir.endsWith("/") 
                        ? currentDir + name 
                        : currentDir + "/" + name;
                    
                    directories.add(fullPath);
                    toExplore.add(fullPath);
                    dirCount++;
                    
                    if (dirCount % 1000 == 0) {
                        log.info("Discovered {} directories...", dirCount);
                    }
                }
            }
        }
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/domain/service/FileMetadataService.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.domain.service;

import com.indra.minsait.dvsmart.indexing.domain.model.ArchivoMetadata;
import com.indra.minsait.dvsmart.indexing.domain.model.SftpFileEntry;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import java.nio.charset.StandardCharsets;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.time.Instant;


/**
 * Author: hahuaranga@indracompany.com
 * Created on: 16-12-2025 at 13:56:41
 * File: FileMetadataService.java
 */

/**
 * Servicio de dominio para procesar metadata de archivos.
 * LÃ³gica pura sin dependencias de frameworks.
 */
@Slf4j
@Service
public class FileMetadataService {

	/**
	 * Convierte un SftpFileEntry a ArchivoMetadata con todos los campos calculados.
	 */
	public ArchivoMetadata toMetadata(SftpFileEntry entry) {
	    String extension = extractExtension(entry.getFilename());
	    String idUnico = generateIdUnico(entry.getFullPath());
	    
	    try {
			return ArchivoMetadata.builder()
			        .idUnico(idUnico)
			        .sourcePath(entry.getFullPath())              // âœ… CAMBIO
			        .fileName(entry.getFilename())                // âœ… CAMBIO
			        .extension(extension)
			        .fileSize(entry.getSize())                    // âœ… CAMBIO
			        .lastModificationDate(
			            Instant.ofEpochMilli(entry.getModificationTime())  // âœ… CAMBIO
			        )
			        // âœ… NUEVO: Estado inicial de indexaciÃ³n
			        .indexing_status("COMPLETED")                 // âœ… NUEVO
			        .indexing_indexedAt(Instant.now())            // âœ… NUEVO
			        .build();
		} catch (Exception e) {
	        // Retornar metadata con error
	        return ArchivoMetadata.builder()
	                .idUnico(String.valueOf(entry.getFullPath().hashCode()))
	                .sourcePath(entry.getFullPath())
	                .fileName(entry.getFilename())
	                .fileSize(entry.getSize())
	                .indexing_status("FAILED")
	                .indexing_indexedAt(Instant.now())
	                .indexing_errorDescription(e.getMessage())
	                .build();
		}
	}

    /**
     * Genera un ID Ãºnico basado en el path completo usando SHA-256.
     */
    public String generateIdUnico(String fullPath) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            byte[] hashBytes = digest.digest(fullPath.getBytes(StandardCharsets.UTF_8));
            return bytesToHex(hashBytes);
        } catch (NoSuchAlgorithmException e) {
            log.error("SHA-256 algorithm not available", e);
            throw new RuntimeException("Failed to generate unique ID", e);
        }
    }

    /**
     * Extrae la extensiÃ³n del archivo.
     */
    private String extractExtension(String filename) {
        if (filename == null || !filename.contains(".")) {
            return "";
        }
        int lastDot = filename.lastIndexOf('.');
        return filename.substring(lastDot + 1).toLowerCase();
    }

    private String bytesToHex(byte[] bytes) {
        StringBuilder hexString = new StringBuilder();
        for (byte b : bytes) {
            String hex = Integer.toHexString(0xff & b);
            if (hex.length() == 1) {
                hexString.append('0');
            }
            hexString.append(hex);
        }
        return hexString.toString();
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/config/BatchConfigProperties.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.config;

import lombok.Getter;
import lombok.Setter;
import org.springframework.boot.context.properties.ConfigurationProperties;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 12:25:45
 * File: BatchConfigProperties.java
 */

@Getter
@Setter
@ConfigurationProperties(prefix = "batch")
public class BatchConfigProperties {
    private int chunkSize = 100;
    //private int concurrencyLimit = 10;
    private int threadPoolSize = 20;
    private int queueCapacity = 1000;
    private int retryLimit = 3;
    private int skipLimit = 5;
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/config/SftpConfigProperties.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.config;

import lombok.Getter;
import lombok.Setter;
import org.springframework.boot.context.properties.ConfigurationProperties;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 11:03:22
 * File: SftpConfigProperties.java
 */

@Getter
@Setter
@ConfigurationProperties(prefix = "sftp")
public class SftpConfigProperties {
    
    private Origin origin = new Origin();
    
    @Getter
    @Setter
    public static class Origin {
        private String host;
        private int port = 22;
        private String user;
        private String password;
        private String baseDir;
        private int timeout = 30000;
        private Pool pool = new Pool();
    }
    
    @Getter
    @Setter
    public static class Pool {
        // TamaÃ±o del pool
        private int size = 10;
        private int maxSize = 10;
        private int initialSize = 0;
        
        // ConfiguraciÃ³n lazy
        private boolean lazyInit = true;
        
        // Timeouts y validaciÃ³n
        private long maxWaitMillis = 30000;
        private boolean testOnBorrow = true;
        private boolean testWhileIdle = true;
        
        // Eviction (limpieza de conexiones inactivas)
        private long timeBetweenEvictionRunsMillis = 60000;
        private long minEvictableIdleTimeMillis = 300000; // 5 minutos
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/exception/GlobalExceptionHandler.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.exception;

import lombok.extern.slf4j.Slf4j;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.RestControllerAdvice;
import java.time.Instant;
import java.util.Map;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 13:26:24
 * File: GlobalExceptionHandler.java
 */

@Slf4j
@RestControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(RuntimeException.class)
    public ResponseEntity<Map<String, Object>> handleRuntimeException(RuntimeException ex) {
        log.error("Runtime exception occurred", ex);
        
        return ResponseEntity
                .status(HttpStatus.INTERNAL_SERVER_ERROR)
                .body(Map.of(
                    "timestamp", Instant.now().toString(),
                    "status", HttpStatus.INTERNAL_SERVER_ERROR.value(),
                    "error", "Internal Server Error",
                    "message", ex.getMessage() != null ? ex.getMessage() : "An unexpected error occurred"
                ));
    }

    @ExceptionHandler(IllegalArgumentException.class)
    public ResponseEntity<Map<String, Object>> handleIllegalArgumentException(IllegalArgumentException ex) {
        log.error("Illegal argument exception occurred", ex);
        
        return ResponseEntity
                .status(HttpStatus.BAD_REQUEST)
                .body(Map.of(
                    "timestamp", Instant.now().toString(),
                    "status", HttpStatus.BAD_REQUEST.value(),
                    "error", "Bad Request",
                    "message", ex.getMessage() != null ? ex.getMessage() : "Invalid request parameters"
                ));
    }

    @ExceptionHandler(Exception.class)
    public ResponseEntity<Map<String, Object>> handleGenericException(Exception ex) {
        log.error("Unexpected exception occurred", ex);
        
        return ResponseEntity
                .status(HttpStatus.INTERNAL_SERVER_ERROR)
                .body(Map.of(
                    "timestamp", Instant.now().toString(),
                    "status", HttpStatus.INTERNAL_SERVER_ERROR.value(),
                    "error", "Internal Server Error",
                    "message", "An unexpected error occurred"
                ));
    }
    
    /**
     * Maneja el caso cuando se intenta ejecutar un job que ya estÃ¡ corriendo.
     * Retorna HTTP 409 CONFLICT con mensaje descriptivo.
     */
    @ExceptionHandler(JobAlreadyRunningException.class)
    public ResponseEntity<Map<String, Object>> handleJobAlreadyRunning(JobAlreadyRunningException ex) {
        log.warn("Job execution conflict: {}", ex.getMessage());
        
        return ResponseEntity
                .status(HttpStatus.CONFLICT)
                .body(Map.of(
                    "timestamp", Instant.now().toString(),
                    "status", HttpStatus.CONFLICT.value(),
                    "error", "Conflict",
                    "message", ex.getMessage(),
                    "detail", "Please wait for the current job to complete before starting a new one"
                ));
    }    
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/exception/JobAlreadyRunningException.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.exception;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 17-12-2025 at 22:18:46
 * File: JobAlreadyRunningException.java
 */

/**
 * ExcepciÃ³n lanzada cuando se intenta ejecutar un job que ya estÃ¡ en ejecuciÃ³n.
 * El GlobalExceptionHandler la mapea a HTTP 409 CONFLICT.
 */
public class JobAlreadyRunningException extends RuntimeException {
    
	private static final long serialVersionUID = 1L;

	public JobAlreadyRunningException(String message) {
        super(message);
    }
    
    public JobAlreadyRunningException(String message, Throwable cause) {
        super(message, cause);
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/sftp/CustomLazySftpSessionFactory.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.sftp;

import lombok.extern.slf4j.Slf4j;
import org.apache.commons.pool2.impl.GenericObjectPool;
import org.apache.commons.pool2.impl.GenericObjectPoolConfig;
import org.apache.sshd.sftp.client.SftpClient;
import org.springframework.integration.file.remote.session.Session;
import org.springframework.integration.file.remote.session.SessionFactory;
import java.io.IOException;
import java.time.Duration;


/**
 * Author: hahuaranga@indracompany.com
 * Created on: 18-12-2025 at 16:17:20
 * File: CustomLazySftpSessionFactory.java
 */

/**
 * SessionFactory personalizado con pool lazy y validaciÃ³n de conexiones.
 * 
 * CaracterÃ­sticas:
 * - Pool lazy: Conexiones creadas bajo demanda
 * - ValidaciÃ³n pre-uso: Verifica salud antes de retornar
 * - Eviction: Cierra conexiones inactivas automÃ¡ticamente
 * - Thread-safe: Seguro para uso concurrente
 */
@Slf4j
public class CustomLazySftpSessionFactory implements SessionFactory<SftpClient.DirEntry> {

    private final GenericObjectPool<Session<SftpClient.DirEntry>> pool;
    private final SftpSessionPooledObjectFactory pooledFactory;

    public CustomLazySftpSessionFactory(
            SessionFactory<SftpClient.DirEntry> targetFactory,
            int maxPoolSize,
            int initialSize,
            long maxWaitMillis,
            boolean testOnBorrow,
            long timeBetweenEvictionRunsMillis,
            long minEvictableIdleTimeMillis) {

        log.info("Initializing Lazy SFTP Session Pool: maxSize={}, initialSize={}, lazy={}",
                maxPoolSize, initialSize, initialSize == 0);

        // Factory que crea sesiones bajo demanda
        this.pooledFactory = new SftpSessionPooledObjectFactory(targetFactory);

        // ConfiguraciÃ³n del pool
        GenericObjectPoolConfig<Session<SftpClient.DirEntry>> config = new GenericObjectPoolConfig<>();
        
        // TamaÃ±o del pool
        config.setMaxTotal(maxPoolSize);
        config.setMaxIdle(maxPoolSize);
        config.setMinIdle(0); // No mantener sesiones mÃ­nimas
        
        // Comportamiento LIFO (Last In First Out) para reusar conexiones recientes
        config.setLifo(true);
        
        // Timeouts
        config.setMaxWait(Duration.ofMillis(maxWaitMillis));
        
        // ValidaciÃ³n
        config.setTestOnBorrow(testOnBorrow);
        config.setTestWhileIdle(true);
        config.setTestOnReturn(false);
        
        // Eviction (limpieza de inactivas)
        config.setTimeBetweenEvictionRuns(Duration.ofMillis(timeBetweenEvictionRunsMillis));
        config.setMinEvictableIdleTime(Duration.ofMillis(minEvictableIdleTimeMillis));
        config.setNumTestsPerEvictionRun(3);
        
        // Crear pool
        this.pool = new GenericObjectPool<>(pooledFactory, config);
        
        // Pre-crear sesiones iniciales si se especifica
        if (initialSize > 0) {
            log.info("Pre-creating {} initial sessions...", initialSize);
            for (int i = 0; i < initialSize; i++) {
                try {
                    pool.addObject();
                } catch (Exception e) {
                    log.warn("Failed to pre-create session {}", i, e);
                }
            }
        }
        
        log.info("SFTP Session Pool initialized successfully");
    }

    @Override
    public Session<SftpClient.DirEntry> getSession() {
        try {
            log.debug("Borrowing session from pool (active={}, idle={})",
                    pool.getNumActive(), pool.getNumIdle());
            
            Session<SftpClient.DirEntry> session = pool.borrowObject();
            
            log.debug("Session borrowed successfully (active={}, idle={})",
                    pool.getNumActive(), pool.getNumIdle());
            
            return new PooledSftpSession(session, pool);
            
        } catch (Exception e) {
            log.error("Failed to borrow session from pool", e);
            throw new RuntimeException("Could not obtain SFTP session", e);
        }
    }

    /**
     * Wrapper que devuelve la sesiÃ³n al pool al cerrarse.
     */
    private static class PooledSftpSession implements Session<SftpClient.DirEntry> {
        
        private final Session<SftpClient.DirEntry> delegate;
        private final GenericObjectPool<Session<SftpClient.DirEntry>> pool;
        private volatile boolean closed = false;

        public PooledSftpSession(
                Session<SftpClient.DirEntry> delegate,
                GenericObjectPool<Session<SftpClient.DirEntry>> pool) {
            this.delegate = delegate;
            this.pool = pool;
        }

        @Override
        public void close() {
            if (!closed) {
                closed = true;
                try {
                    log.debug("Returning session to pool");
                    pool.returnObject(delegate);
                } catch (Exception e) {
                    log.warn("Error returning session to pool", e);
                }
            }
        }

        @Override
        public boolean remove(String path) throws IOException {
            return delegate.remove(path);
        }

        @Override
        public SftpClient.DirEntry[] list(String path) throws IOException {
            return delegate.list(path);
        }

        @Override
        public void read(String source, java.io.OutputStream outputStream) throws IOException {
            delegate.read(source, outputStream);
        }

        @Override
        public void write(java.io.InputStream inputStream, String destination) throws IOException {
            delegate.write(inputStream, destination);
        }

        @Override
        public void append(java.io.InputStream inputStream, String destination) throws IOException {
            delegate.append(inputStream, destination);
        }

        @Override
        public boolean mkdir(String directory) throws IOException {
            return delegate.mkdir(directory);
        }

        @Override
        public boolean rmdir(String directory) throws IOException {
            return delegate.rmdir(directory);
        }

        @Override
        public void rename(String pathFrom, String pathTo) throws IOException {
            delegate.rename(pathFrom, pathTo);
        }

        @Override
        public boolean isOpen() {
            return !closed && delegate.isOpen();
        }

        @Override
        public boolean exists(String path) throws IOException {
            return delegate.exists(path);
        }

        @Override
        public String[] listNames(String path) throws IOException {
            return delegate.listNames(path);
        }

        @Override
        public java.io.InputStream readRaw(String source) throws IOException {
            return delegate.readRaw(source);
        }

        @Override
        public boolean finalizeRaw() throws IOException {
            return delegate.finalizeRaw();
        }

        @Override
        public Object getClientInstance() {
            return delegate.getClientInstance();
        }

        @Override
        public String getHostPort() {
            return delegate.getHostPort();
        }
    }

    /**
     * Retorna estadÃ­sticas del pool (Ãºtil para monitoring).
     */
    public PoolStats getStats() {
        return new PoolStats(
            pool.getNumActive(),
            pool.getNumIdle(),
            pool.getMaxTotal(),
            pool.getCreatedCount(),
            pool.getDestroyedCount()
        );
    }

    public record PoolStats(
        int active,
        int idle,
        int maxTotal,
        long created,
        long destroyed
    ) {}

    /**
     * Cierra el pool y todas sus conexiones.
     */
    public void destroy() {
        log.info("Closing SFTP session pool...");
        pool.close();
        log.info("SFTP session pool closed");
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/sftp/SftpPoolMonitor.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.sftp;

import com.indra.minsait.dvsmart.indexing.infrastructure.sftp.CustomLazySftpSessionFactory.PoolStats;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;
import java.time.Instant;
import java.util.concurrent.atomic.AtomicLong;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 18-12-2025 at 16:43:05
 * File: SftpPoolMonitor.java
 */

/**
 * Monitor del pool de conexiones SFTP.
 * 
 * Responsabilidades:
 * - Exponer mÃ©tricas del pool para endpoints
 * - Log periÃ³dico de estadÃ­sticas
 * - Detectar anomalÃ­as (opcional)
 * - IntegraciÃ³n con actuator/prometheus (futuro)
 */
@Slf4j
@Component
public class SftpPoolMonitor {

    private final CustomLazySftpSessionFactory factory;
    
    // MÃ©tricas adicionales
    private final AtomicLong totalBorrowCount = new AtomicLong(0);
    private final AtomicLong totalReturnCount = new AtomicLong(0);
    private final AtomicLong totalFailures = new AtomicLong(0);
    private volatile Instant lastLogTime = Instant.now();

    public SftpPoolMonitor(CustomLazySftpSessionFactory factory) {
        this.factory = factory;
        log.info("SFTP Pool Monitor initialized");
    }

    /**
     * Obtiene estadÃ­sticas actuales del pool.
     */
    public PoolStats getStats() {
        if (factory == null) {
            return new PoolStats(0, 0, 0, 0, 0);
        }
        return factory.getStats();
    }

    /**
     * Log manual de estadÃ­sticas.
     */
    public void logStats() {
        if (factory == null) {
            log.warn("SFTP Pool Monitor: Factory not initialized");
            return;
        }
        
        PoolStats stats = factory.getStats();
        
        log.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
        log.info("â•‘         SFTP POOL STATISTICS                       â•‘");
        log.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
        log.info("â•‘ Active Connections:      {:>4}                     â•‘", stats.active());
        log.info("â•‘ Idle Connections:        {:>4}                     â•‘", stats.idle());
        log.info("â•‘ Max Pool Size:           {:>4}                     â•‘", stats.maxTotal());
        log.info("â•‘ Total Created:           {:>4}                     â•‘", stats.created());
        log.info("â•‘ Total Destroyed:         {:>4}                     â•‘", stats.destroyed());
        log.info("â•‘ Utilization:             {:>3.1f}%                   â•‘", calculateUtilization(stats));
        log.info("â•‘ Available Slots:         {:>4}                     â•‘", stats.maxTotal() - stats.active());
        log.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        
        lastLogTime = Instant.now();
    }

    /**
     * Log periÃ³dico automÃ¡tico (cada 5 minutos).
     * Ãštil para monitoreo pasivo.
     */
    @Scheduled(fixedRate = 300000) // 5 minutos
    public void scheduledLogStats() {
        logStats();
    }

    /**
     * Detectar anomalÃ­as en el pool.
     * Se ejecuta cada minuto.
     */
    @Scheduled(fixedRate = 60000) // 1 minuto
    public void checkPoolHealth() {
        if (factory == null) return;
        
        PoolStats stats = factory.getStats();
        
        // Alerta: Pool saturado
        if (stats.active() >= stats.maxTotal() * 0.9) {
            log.warn("âš ï¸  SFTP Pool near capacity: {}/{} connections active", 
                     stats.active(), stats.maxTotal());
        }
        
        // Alerta: Muchas conexiones destruidas (posible problema de red)
        if (stats.destroyed() > stats.created() * 0.5 && stats.created() > 10) {
            log.warn("âš ï¸  High connection destruction rate: {} destroyed / {} created", 
                     stats.destroyed(), stats.created());
        }
        
        // Info: Pool completamente idle
        if (stats.active() == 0 && stats.idle() > 0) {
            log.debug("â„¹ï¸  SFTP Pool idle: {} connections available", stats.idle());
        }
    }

    /**
     * Calcula porcentaje de utilizaciÃ³n del pool.
     */
    private double calculateUtilization(PoolStats stats) {
        if (stats.maxTotal() == 0) return 0.0;
        return (double) stats.active() / stats.maxTotal() * 100.0;
    }

    /**
     * Registra un borrow exitoso (llamado desde el cÃ³digo que usa el pool).
     */
    public void recordBorrow() {
        totalBorrowCount.incrementAndGet();
    }

    /**
     * Registra un return exitoso.
     */
    public void recordReturn() {
        totalReturnCount.incrementAndGet();
    }

    /**
     * Registra una falla al obtener conexiÃ³n.
     */
    public void recordFailure() {
        totalFailures.incrementAndGet();
        log.error("âŒ SFTP Pool failure recorded. Total failures: {}", totalFailures.get());
    }

    /**
     * Retorna mÃ©tricas extendidas (incluye custom counters).
     */
    public ExtendedPoolStats getExtendedStats() {
        PoolStats baseStats = getStats();
        
        return new ExtendedPoolStats(
            baseStats.active(),
            baseStats.idle(),
            baseStats.maxTotal(),
            baseStats.created(),
            baseStats.destroyed(),
            totalBorrowCount.get(),
            totalReturnCount.get(),
            totalFailures.get(),
            calculateUtilization(baseStats),
            lastLogTime
        );
    }

    /**
     * Record extendido con mÃ©tricas adicionales.
     */
    public record ExtendedPoolStats(
        int active,
        int idle,
        int maxTotal,
        long totalCreated,
        long totalDestroyed,
        long totalBorrows,
        long totalReturns,
        long totalFailures,
        double utilizationPercent,
        Instant lastLogTime
    ) {
        public boolean isHealthy() {
            return utilizationPercent < 90.0 && totalFailures < totalBorrows * 0.1;
        }
        
        public String getHealthStatus() {
            if (utilizationPercent > 95.0) return "CRITICAL";
            if (utilizationPercent > 80.0) return "WARNING";
            if (totalFailures > totalBorrows * 0.1) return "DEGRADED";
            return "HEALTHY";
        }
    }

    /**
     * Fuerza la limpieza de conexiones inactivas (Ãºtil para mantenimiento).
     */
    public void forceEviction() {
        log.info("Forcing eviction of idle connections...");
        // El pool de Apache Commons ejecuta eviction automÃ¡ticamente,
        // pero podemos loguearlo para awareness
        logStats();
    }

    /**
     * Reset de contadores (Ãºtil para testing o despuÃ©s de mantenimiento).
     */
    public void resetCounters() {
        totalBorrowCount.set(0);
        totalReturnCount.set(0);
        totalFailures.set(0);
        log.info("SFTP Pool Monitor counters reset");
    }

    /**
     * Verifica si el pool estÃ¡ saludable.
     */
    public boolean isHealthy() {
        return getExtendedStats().isHealthy();
    }

    /**
     * Retorna el estado de salud del pool.
     */
    public String getHealthStatus() {
        return getExtendedStats().getHealthStatus();
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/sftp/SftpSessionFactoryConfig.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.sftp;

import com.indra.minsait.dvsmart.indexing.infrastructure.config.SftpConfigProperties;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.sshd.sftp.client.SftpClient;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.integration.file.remote.session.SessionFactory;
import org.springframework.integration.sftp.session.DefaultSftpSessionFactory;
import org.springframework.integration.sftp.session.SftpRemoteFileTemplate;
import jakarta.annotation.PreDestroy;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 12-12-2025 at 13:05:17
 * File: SftpSessionFactoryConfig.java
 */

/**
 * ConfiguraciÃ³n de SessionFactory con pool lazy y validaciÃ³n.
 */
@Slf4j
@Configuration
@RequiredArgsConstructor
public class SftpSessionFactoryConfig {

    private final SftpConfigProperties props;
    private CustomLazySftpSessionFactory lazyPoolFactory;

    /**
     * Factory base (sin pool) que crea conexiones SFTP individuales.
     */
    private SessionFactory<SftpClient.DirEntry> createBaseSessionFactory() {
        DefaultSftpSessionFactory factory = new DefaultSftpSessionFactory(true);
        factory.setHost(props.getOrigin().getHost());
        factory.setPort(props.getOrigin().getPort());
        factory.setUser(props.getOrigin().getUser());
        factory.setPassword(props.getOrigin().getPassword());
        factory.setTimeout(props.getOrigin().getTimeout());
        factory.setAllowUnknownKeys(true);
        
        log.info("Base SFTP SessionFactory configured for {}:{}",
                props.getOrigin().getHost(),
                props.getOrigin().getPort());
        
        return factory;
    }

    /**
     * SessionFactory con pool lazy personalizado.
     * 
     * Ventajas:
     * - Conexiones creadas bajo demanda
     * - ValidaciÃ³n pre-uso automÃ¡tica
     * - Eviction de conexiones inactivas
     * - CoordinaciÃ³n con otras APIs vÃ­a uso responsable
     */
    @Bean(name = "sftpOriginSessionFactory")
    SessionFactory<SftpClient.DirEntry> sftpOriginSessionFactory() {
        
        SessionFactory<SftpClient.DirEntry> baseFactory = createBaseSessionFactory();
        
        SftpConfigProperties.Pool poolConfig = props.getOrigin().getPool();
        
        lazyPoolFactory = new CustomLazySftpSessionFactory(
            baseFactory,
            poolConfig.getMaxSize(),
            poolConfig.getInitialSize(),
            poolConfig.getMaxWaitMillis(),
            poolConfig.isTestOnBorrow(),
            poolConfig.getTimeBetweenEvictionRunsMillis(),
            poolConfig.getMinEvictableIdleTimeMillis()
        );
        
        log.info("Lazy SFTP Session Pool initialized with max size: {}", poolConfig.getMaxSize());
        
        return lazyPoolFactory;
    }

    /**
     * Template para operaciones SFTP de alto nivel.
     */
    @Bean(name = "sftpOriginTemplate")
    SftpRemoteFileTemplate sftpOriginTemplate() {
        SftpRemoteFileTemplate template = new SftpRemoteFileTemplate(sftpOriginSessionFactory());
        log.info("SFTP RemoteFileTemplate configured");
        return template;
    }

    /**
     * Monitor del pool como bean independiente.
     */
    @Bean
    SftpPoolMonitor sftpPoolMonitor() {
        return new SftpPoolMonitor(lazyPoolFactory);
    }

    /**
     * Limpieza al apagar la aplicaciÃ³n.
     */
    @PreDestroy
    public void cleanup() {
        if (lazyPoolFactory != null) {
            log.info("Shutting down SFTP session pool...");
            lazyPoolFactory.destroy();
        }
    }
}-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/infrastructure/sftp/SftpSessionPooledObjectFactory.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing.infrastructure.sftp;

import lombok.extern.slf4j.Slf4j;
import org.apache.commons.pool2.BasePooledObjectFactory;
import org.apache.commons.pool2.PooledObject;
import org.apache.commons.pool2.impl.DefaultPooledObject;
import org.apache.sshd.sftp.client.SftpClient;
import org.springframework.integration.file.remote.session.Session;
import org.springframework.integration.file.remote.session.SessionFactory;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 18-12-2025 at 16:19:05
 * File: SftpSessionPooledObjectFactory.java
 */
	
/**
 * Factory que gestiona el ciclo de vida de las sesiones SFTP en el pool.
 * 
 * Responsabilidades:
 * - Crear nuevas sesiones bajo demanda
 * - Validar salud de sesiones existentes
 * - Destruir sesiones invÃ¡lidas o cerradas
 */
@Slf4j
public class SftpSessionPooledObjectFactory extends BasePooledObjectFactory<Session<SftpClient.DirEntry>> {

    private final SessionFactory<SftpClient.DirEntry> targetFactory;

    public SftpSessionPooledObjectFactory(SessionFactory<SftpClient.DirEntry> targetFactory) {
        this.targetFactory = targetFactory;
    }

    /**
     * Crea una nueva sesiÃ³n SFTP.
     * Llamado por el pool cuando necesita una nueva conexiÃ³n.
     */
    @Override
    public Session<SftpClient.DirEntry> create() throws Exception {
        log.debug("Creating new SFTP session...");
        
        try {
            Session<SftpClient.DirEntry> session = targetFactory.getSession();
            
            // Verificar que la sesiÃ³n estÃ¡ realmente abierta
            if (!session.isOpen()) {
                throw new IllegalStateException("Created session is not open");
            }
            
            log.debug("New SFTP session created successfully: {}", session.getHostPort());
            return session;
            
        } catch (Exception e) {
            log.error("Failed to create SFTP session", e);
            throw e;
        }
    }

    /**
     * Envuelve la sesiÃ³n en un PooledObject.
     */
    @Override
    public PooledObject<Session<SftpClient.DirEntry>> wrap(Session<SftpClient.DirEntry> session) {
        return new DefaultPooledObject<>(session);
    }

    /**
     * Valida que una sesiÃ³n sigue siendo vÃ¡lida antes de prestarla.
     * Crucial para detectar conexiones muertas.
     */
    @Override
    public boolean validateObject(PooledObject<Session<SftpClient.DirEntry>> p) {
        Session<SftpClient.DirEntry> session = p.getObject();
        
        try {
            // VerificaciÃ³n bÃ¡sica: estÃ¡ abierta
            if (!session.isOpen()) {
                log.debug("Session validation failed: not open");
                return false;
            }
            
            // VerificaciÃ³n avanzada: hacer un comando simple (pwd o ls /)
            // Esto detecta conexiones "zombie" que parecen abiertas pero estÃ¡n muertas
            session.list("/");
            
            log.trace("Session validation passed: {}", session.getHostPort());
            return true;
            
        } catch (Exception e) {
            log.warn("Session validation failed: {}", e.getMessage());
            return false;
        }
    }

    /**
     * Destruye una sesiÃ³n cuando ya no es vÃ¡lida o el pool la descarta.
     */
    @Override
    public void destroyObject(PooledObject<Session<SftpClient.DirEntry>> p) throws Exception {
        Session<SftpClient.DirEntry> session = p.getObject();
        
        try {
            if (session != null && session.isOpen()) {
                log.debug("Destroying SFTP session: {}", session.getHostPort());
                session.close();
            }
        } catch (Exception e) {
            log.warn("Error destroying SFTP session", e);
        }
    }

    /**
     * Llamado cuando una sesiÃ³n se devuelve al pool.
     * AquÃ­ se puede hacer limpieza si es necesario.
     */
    @Override
    public void passivateObject(PooledObject<Session<SftpClient.DirEntry>> p) throws Exception {
        // No hacer nada especial, la sesiÃ³n puede reutilizarse directamente
        log.trace("Session returned to pool (idle)");
    }

    /**
     * Llamado cuando una sesiÃ³n se saca del pool para uso.
     */
    @Override
    public void activateObject(PooledObject<Session<SftpClient.DirEntry>> p) throws Exception {
        // Verificar que sigue abierta
        Session<SftpClient.DirEntry> session = p.getObject();
        
        if (!session.isOpen()) {
            throw new IllegalStateException("Session is not open");
        }
        
        log.trace("Session activated from pool");
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/java/com/indra/minsait/dvsmart/indexing/ServiceApplication.java
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
/*
 * /////////////////////////////////////////////////////////////////////////////
 *
 * Copyright (c) 2025 Indra Sistemas, S.A. All Rights Reserved.
 * http://www.indracompany.com/
 *
 * The contents of this file are owned by Indra Sistemas, S.A. copyright holder.
 * This file can only be copied, distributed and used all or in part with the
 * written permission of Indra Sistemas, S.A, or in accordance with the terms and
 * conditions laid down in the agreement / contract under which supplied.
 *
 * /////////////////////////////////////////////////////////////////////////////
 */
package com.indra.minsait.dvsmart.indexing;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.context.properties.ConfigurationPropertiesScan;

/**
 * Author: hahuaranga@indracompany.com
 * Created on: 11-12-2025 at 17:07:25
 * File: ServiceApplication.java
 */

@SpringBootApplication
@ConfigurationPropertiesScan
public class ServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(ServiceApplication.class, args);
    }
}
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./src/main/resources/application.properties
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================
spring.application.name=dvsmart-indexing-api
server.servlet.context-path=/dvsmart_indexing_api
server.port=8080

# ============================================================================
# MONGODB CONFIGURATION
# ============================================================================
#spring.mongodb.uri=mongodb://dvsmart_user:eoQQqfTyMd@dvsmart-catalog-mongodb.dvsmart.svc.cluster.local:27017/dvsmart-ms?authSource=dvsmart-ms
spring.mongodb.uri=mongodb://dvsmart_user:eoQQqfTyMd@localhost:30000/dvsmart-ms?authSource=dvsmart-ms

# PostgreSQL Database (para Spring Batch)
#spring.datasource.url=jdbc:postgresql://dvsmart-batch-postgresql.dvsmart.svc.cluster.local:5432/dvsmart
spring.datasource.url=jdbc:postgresql://localhost:30005/dvsmart
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.username=dvsmart_ms
spring.datasource.password=OgxjdNEeQl
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=5

spring.batch.job.enabled=false
spring.batch.jdbc.initialize-schema=always

# ============================================================================
# BATCH CUSTOM PROPERTIES (BatchConfigProperties)
# ============================================================================
# Tamanio del chunk para procesamiento por lotes
# Cada chunk procesa este numero de registros antes de commit
batch.chunk-size=100

# Tamanio del pool de threads para procesamiento asincrono
# Mas threads = mas procesamiento paralelo (balance con recursos del servidor)
batch.thread-pool-size=20

# Capacidad de la cola de tareas pendientes
# Si hay mas tareas que threads, se encolan aqui
batch.queue-capacity=1000

batch.skip-limit=5

batch.retry-limit=3

# ============================================================================
# SFTP ORIGIN CONFIGURATION (SftpConfigProperties.Origin)
# ============================================================================
# Servidor SFTP de origen (donde estan los archivos actuales)
#sftp.origin.host=dvsmart-source-filesystem-sftp.dvsmart.svc.cluster.local
sftp.origin.host=localhost
#sftp.origin.port=22
sftp.origin.port=30002
sftp.origin.user=sftpsourceuser
sftp.origin.password=securepass

# Directorio base en el servidor origen
sftp.origin.base-dir=/disorganized_data

# Timeout de conexion en milisegundos (30 segundos)
sftp.origin.timeout=30000

# Tamanio del pool de conexiones SFTP origen
# Mas conexiones = mas operaciones simultaneas de lectura
sftp.origin.pool.size=10

# ============================================================================
# SFTP POOL CONFIGURATION (Lazy + Health Check)
# ============================================================================
# Pool lazy: no crear conexiones al inicio
sftp.origin.pool.lazy-init=true

# Tamanio inicial del pool (0 = completamente lazy)
sftp.origin.pool.initial-size=0

# Tamanio maximo del pool
sftp.origin.pool.max-size=10

# Tiempo maximo de espera por una conexion (ms)
sftp.origin.pool.max-wait-millis=30000

# Validar conexion antes de usarla
sftp.origin.pool.test-on-borrow=true

# Validar conexiones inactivas cada X ms
sftp.origin.pool.time-between-eviction-runs-millis=60000

# Tiempo maximo de inactividad antes de cerrar conexion (ms)
# 5 minutos (menor que el timeout del servidor de 10 min)
sftp.origin.pool.min-evictable-idle-time-millis=300000

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================
# Nivel de log general
logging.level.root=INFO

# Logs de la aplicacion (ajustar segun necesidad)
logging.level.com.indra.minsait.dvsmart.indexing=DEBUG

# Logs de Spring Batch (INFO para produccion, DEBUG para desarrollo)
logging.level.org.springframework.batch=INFO

# Logs de Spring Integration SFTP (DEBUG para troubleshooting)
logging.level.org.springframework.integration.sftp=DEBUG

# Logs de MongoDB
logging.level.org.springframework.data.mongodb=INFO

# Patron de log para consola
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %logger{36} - %msg%n

# Logging especifico para ShedLock
logging.level.net.javacrumbs.shedlock=DEBUG

# ============================================================================
# ACTUATOR CONFIGURATION (Monitoring & Health)
# ============================================================================
# Exponer endpoints de actuator
management.endpoints.web.exposure.include=health,info,metrics,batch

# Mostrar detalles del health check
management.endpoint.health.show-details=always

# Habilitar metricas de JVM, proceso y sistema
management.metrics.enable.jvm=true
management.metrics.enable.process=true
management.metrics.enable.system=true-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./target/classes/application.properties
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================
spring.application.name=dvsmart-indexing-api
server.servlet.context-path=/dvsmart_indexing_api
server.port=8080

# ============================================================================
# MONGODB CONFIGURATION
# ============================================================================
#spring.mongodb.uri=mongodb://dvsmart_user:eoQQqfTyMd@dvsmart-catalog-mongodb.dvsmart.svc.cluster.local:27017/dvsmart-ms?authSource=dvsmart-ms
spring.mongodb.uri=mongodb://dvsmart_user:eoQQqfTyMd@localhost:30000/dvsmart-ms?authSource=dvsmart-ms

# PostgreSQL Database (para Spring Batch)
#spring.datasource.url=jdbc:postgresql://dvsmart-batch-postgresql.dvsmart.svc.cluster.local:5432/dvsmart
spring.datasource.url=jdbc:postgresql://localhost:30005/dvsmart
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.username=dvsmart_ms
spring.datasource.password=OgxjdNEeQl
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=5

spring.batch.job.enabled=false
spring.batch.jdbc.initialize-schema=always

# ============================================================================
# BATCH CUSTOM PROPERTIES (BatchConfigProperties)
# ============================================================================
# Tamanio del chunk para procesamiento por lotes
# Cada chunk procesa este numero de registros antes de commit
batch.chunk-size=100

# Tamanio del pool de threads para procesamiento asincrono
# Mas threads = mas procesamiento paralelo (balance con recursos del servidor)
batch.thread-pool-size=20

# Capacidad de la cola de tareas pendientes
# Si hay mas tareas que threads, se encolan aqui
batch.queue-capacity=1000

batch.skip-limit=5

batch.retry-limit=3

# ============================================================================
# SFTP ORIGIN CONFIGURATION (SftpConfigProperties.Origin)
# ============================================================================
# Servidor SFTP de origen (donde estan los archivos actuales)
#sftp.origin.host=dvsmart-source-filesystem-sftp.dvsmart.svc.cluster.local
sftp.origin.host=localhost
#sftp.origin.port=22
sftp.origin.port=30002
sftp.origin.user=sftpsourceuser
sftp.origin.password=securepass

# Directorio base en el servidor origen
sftp.origin.base-dir=/disorganized_data

# Timeout de conexion en milisegundos (30 segundos)
sftp.origin.timeout=30000

# Tamanio del pool de conexiones SFTP origen
# Mas conexiones = mas operaciones simultaneas de lectura
sftp.origin.pool.size=10

# ============================================================================
# SFTP POOL CONFIGURATION (Lazy + Health Check)
# ============================================================================
# Pool lazy: no crear conexiones al inicio
sftp.origin.pool.lazy-init=true

# Tamanio inicial del pool (0 = completamente lazy)
sftp.origin.pool.initial-size=0

# Tamanio maximo del pool
sftp.origin.pool.max-size=10

# Tiempo maximo de espera por una conexion (ms)
sftp.origin.pool.max-wait-millis=30000

# Validar conexion antes de usarla
sftp.origin.pool.test-on-borrow=true

# Validar conexiones inactivas cada X ms
sftp.origin.pool.time-between-eviction-runs-millis=60000

# Tiempo maximo de inactividad antes de cerrar conexion (ms)
# 5 minutos (menor que el timeout del servidor de 10 min)
sftp.origin.pool.min-evictable-idle-time-millis=300000

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================
# Nivel de log general
logging.level.root=INFO

# Logs de la aplicacion (ajustar segun necesidad)
logging.level.com.indra.minsait.dvsmart.indexing=DEBUG

# Logs de Spring Batch (INFO para produccion, DEBUG para desarrollo)
logging.level.org.springframework.batch=INFO

# Logs de Spring Integration SFTP (DEBUG para troubleshooting)
logging.level.org.springframework.integration.sftp=DEBUG

# Logs de MongoDB
logging.level.org.springframework.data.mongodb=INFO

# Patron de log para consola
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %logger{36} - %msg%n

# Logging especifico para ShedLock
logging.level.net.javacrumbs.shedlock=DEBUG

# ============================================================================
# ACTUATOR CONFIGURATION (Monitoring & Health)
# ============================================================================
# Exponer endpoints de actuator
management.endpoints.web.exposure.include=health,info,metrics,batch

# Mostrar detalles del health check
management.endpoint.health.show-details=always

# Habilitar metricas de JVM, proceso y sistema
management.metrics.enable.jvm=true
management.metrics.enable.process=true
management.metrics.enable.system=true-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./target/classes/META-INF/maven/com.indra.minsait.dvsmart.indexing/dvsmart_indexing_api/pom.properties
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#Generated by Maven Integration for Eclipse
#Wed Dec 24 12:25:06 CLST 2025
artifactId=dvsmart_indexing_api
groupId=com.indra.minsait.dvsmart.indexing
m2e.projectLocation=D\:\\WORKSPACES\\workspace_eclipse_new_latest\\dvsmart_indexing_api
m2e.projectName=dvsmart_indexing_api
version=1.0.0-SNAPSHOT
-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./target/classes/META-INF/maven/com.indra.minsait.dvsmart.indexing/dvsmart_indexing_api/pom.xml
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
<project xmlns="http://maven.apache.org/POM/4.0.0"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>4.0.1</version>
	</parent>
	<groupId>com.indra.minsait.dvsmart.indexing</groupId>
	<artifactId>dvsmart_indexing_api</artifactId>
	<version>1.0.0-SNAPSHOT</version>
	<name>dvsmart_indexing_api</name>

	<properties>
		<java.version>21</java.version>
		<maven.compiler.source>21</maven.compiler.source>
		<maven.compiler.target>21</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<license.maven.plugin.version>5.0.0</license.maven.plugin.version>
		<maven.build.timestamp.format>yyyy</maven.build.timestamp.format>
		<!-- Other dependencies -->
		<sshj.version>0.38.0</sshj.version>
	</properties>

	<dependencies>
		<!-- Spring Boot Starters -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-validation</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-mongodb</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>

		<!-- Spring Batch -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-batch</artifactId>
		</dependency>

		<!-- Spring Integration Core -->
		<dependency>
			<groupId>org.springframework.integration</groupId>
			<artifactId>spring-integration-core</artifactId>
		</dependency>

		<!-- Spring Integration SFTP (SSHJ) -->
		<dependency>
			<groupId>org.springframework.integration</groupId>
			<artifactId>spring-integration-sftp</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.batch</groupId>
			<artifactId>spring-batch-integration</artifactId>
		</dependency>

		<!-- SSHJ for SFTP -->
		<dependency>
			<groupId>com.hierynomus</groupId>
			<artifactId>sshj</artifactId>
			<version>${sshj.version}</version>
		</dependency>

		<!-- Lombok -->
		<dependency>
			<groupId>org.projectlombok</groupId>
			<artifactId>lombok</artifactId>
			<scope>provided</scope>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-devtools</artifactId>
			<scope>runtime</scope>
			<optional>true</optional>
		</dependency>

		<!-- Spring Boot Configuration Processor -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-configuration-processor</artifactId>
			<optional>true</optional>
		</dependency>

		<!-- Testing -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.springframework.batch</groupId>
			<artifactId>spring-batch-test</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.springframework.integration</groupId>
			<artifactId>spring-integration-test</artifactId>
			<scope>test</scope>
		</dependency>

		<!-- Apache Commons Pool para gestiÃ³n de pool lazy -->
		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-pool2</artifactId>
		</dependency>

	    <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <scope>runtime</scope>
        </dependency> 

		<dependency>
		    <groupId>org.springframework.boot</groupId>
		    <artifactId>spring-boot-starter-jdbc</artifactId>
		</dependency>

	</dependencies>

	<build>
		<finalName>${project.artifactId}</finalName>
		<plugins>

			<!-- Maven Compiler Plugin -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>${java.version}</source>
					<target>${java.version}</target>
					<encoding>${project.build.sourceEncoding}</encoding>
					<annotationProcessorPaths>
						<path>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
							<version>${lombok.version}</version>
						</path>
						<path>
							<groupId>org.springframework.boot</groupId>
							<artifactId>spring-boot-configuration-processor</artifactId>
							<version>4.0.0</version>
						</path>
					</annotationProcessorPaths>
				</configuration>
			</plugin>

			<!-- Spring Boot Maven Plugin -->
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<configuration>
					<excludes>
						<exclude>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</exclude>
					</excludes>
				</configuration>
				<executions>
					<execution>
						<goals>
							<goal>repackage</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- CopyRight Plugin -->
			<plugin>
				<groupId>com.mycila</groupId>
				<artifactId>license-maven-plugin</artifactId>
				<version>${license.maven.plugin.version}</version>
				<configuration>
					<!-- Ruta del banner -->
					<header>src/main/resources/license-header.txt</header>

					<!-- Aplicar solo a archivos donde corresponde -->
					<includes>
						<include>**/*.java</include>
					</includes>

					<!-- Evitar modificar cÃ³digo generado o configuraciones -->
					<excludes>
						<exclude>**/target/**</exclude>
						<exclude>**/generated/**</exclude>
					</excludes>

					<!-- Variables dinÃ¡micas -->
					<properties>
						<year>${maven.build.timestamp}</year>
					</properties>

					<!-- Etiquetas conocidas para insertar correctamente el
					header -->
					<mapping>
						<java>SLASHSTAR_STYLE</java>
					</mapping>

					<!-- Configuraciones adicionales importantes -->
					<strictCheck>true</strictCheck>
					<useDefaultExcludes>true</useDefaultExcludes>
				</configuration>

				<executions>
					<!-- Ejecuta el format en la fase process-sources (antes de
					compile) -->
					<execution>
						<id>apply-license-headers</id>
						<phase>process-sources</phase>
						<goals>
							<goal>format</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- Maven Surefire Plugin (para tests) -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<!--				<version>3.0.0</version>-->
				<configuration>
					<includes>
						<include>**/*Test.java</include>
						<include>**/*Tests.java</include>
					</includes>
				</configuration>
			</plugin>

			<!-- Maven Resources Plugin -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-resources-plugin</artifactId>
				<!--				<version>3.3.1</version>-->
				<configuration>
					<encoding>${project.build.sourceEncoding}</encoding>
				</configuration>
			</plugin>
		</plugins>
	</build>

	<!-- Profiles -->
	<profiles>
		<!-- Development Profile -->
		<profile>
			<id>dev</id>
			<activation>
				<activeByDefault>true</activeByDefault>
			</activation>
			<properties>
				<spring.profiles.active>dev</spring.profiles.active>
			</properties>
		</profile>

		<!-- Production Profile -->
		<profile>
			<id>prod</id>
			<properties>
				<spring.profiles.active>prod</spring.profiles.active>
			</properties>
		</profile>
	</profiles>

</project>-e /n/n
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ARCHIVO: ./target/maven-archiver/pom.properties
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
artifactId=dvsmart_indexing_api
groupId=com.indra.minsait.dvsmart.indexing
version=1.0.0-SNAPSHOT
-e /n/n
